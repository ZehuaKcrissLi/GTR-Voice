{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# extract features via librosa\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "audio = '/Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_55_333231/01.wav'\n",
    "y, sr = librosa.load(audio)\n",
    "\n",
    "# get stft of audio\n",
    "stft = librosa.stft(y)\n",
    "\n",
    "# extract mfcc\n",
    "mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
    "\n",
    "# extract mel\n",
    "mel = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "\n",
    "# extract contrast\n",
    "contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "\n",
    "# extract spectral centroid\n",
    "spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "\n",
    "# extract spectral bandwidth\n",
    "spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "\n",
    "# extract spectral rolloff\n",
    "spec_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr, roll_percent=0.99)\n",
    "spec_rolloff_min = librosa.feature.spectral_rolloff(y=y, sr=sr, roll_percent=0.01)\n",
    "\n",
    "# extract pitch(f0) from time series\n",
    "f0, voiced_flag, voiced_probs = librosa.pyin(y,\n",
    "                                             fmin=librosa.note_to_hz('C2'),\n",
    "                                             fmax=librosa.note_to_hz('C7'))\n",
    "f0 = f0[np.newaxis, :]\n",
    "voiced_flag = voiced_flag[np.newaxis, :]\n",
    "voiced_probs = voiced_probs[np.newaxis, :]\n",
    "\n",
    "times_f0 = librosa.times_like(f0)\n",
    "# extract zero crossing rate\n",
    "zcr = librosa.feature.zero_crossing_rate(y=y)\n",
    "\n",
    "# extract flatness\n",
    "flatness = librosa.feature.spectral_flatness(y=y)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-17T13:13:13.299872Z",
     "start_time": "2024-02-17T13:13:11.672865Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T13:13:13.305801Z",
     "start_time": "2024-02-17T13:13:13.304064Z"
    }
   },
   "outputs": [],
   "source": [
    "# feature extractor class\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "class FeatureExtractor:\n",
    "    def __init__(self, sr=22050):\n",
    "        self.sr = sr\n",
    "\n",
    "    def extract_features(self, audio_path):\n",
    "        y, sr = librosa.load(audio_path, sr=self.sr)\n",
    "        \n",
    "        # # extract mfcc\n",
    "        # mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
    "        #\n",
    "        # # extract mel\n",
    "        # mel = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "        #\n",
    "        # # extract contrast\n",
    "        # contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "        #\n",
    "        # # extract spectral centroid\n",
    "        # spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "        #\n",
    "        # # extract spectral bandwidth\n",
    "        # spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "        #\n",
    "        # # extract spectral rolloff\n",
    "        # spec_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr, roll_percent=0.99)\n",
    "        # spec_rolloff_min = librosa.feature.spectral_rolloff(y=y, sr=sr, roll_percent=0.01)\n",
    "\n",
    "        # extract pitch(f0) from time series\n",
    "        f0, voiced_flag, voiced_probs = librosa.pyin(y,\n",
    "                                                     fmin=librosa.note_to_hz('C2'),\n",
    "                                                     fmax=librosa.note_to_hz('C7'),\n",
    "                                                     fill_na=0.0)\n",
    "        f0 = f0[np.newaxis, :]\n",
    "        voiced_flag = voiced_flag[np.newaxis, :]\n",
    "        voiced_probs = voiced_probs[np.newaxis, :]\n",
    "        \n",
    "        # # extract zero crossing rate\n",
    "        # zcr = librosa.feature.zero_crossing_rate(y=y)\n",
    "        #\n",
    "        # # extract flatness\n",
    "        # flatness = librosa.feature.spectral_flatness(y=y)\n",
    "        \n",
    "        # concatenate all features\n",
    "        # features = np.concatenate((mfcc, mel, contrast, spec_cent, spec_bw, spec_rolloff, spec_rolloff_min, f0, voiced_flag, voiced_probs, zcr, flatness), axis=0)\n",
    "        features = np.concatenate((f0, voiced_probs), axis=0)\n",
    "        # Aggregate features\n",
    "        # features = np.nan_to_num(features, nan=0.0)\n",
    "        # features[~np.isfinite(features)] = 0\n",
    "        features = np.vstack((np.mean(features, axis=1))).flatten()\n",
    "        \n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T13:13:51.937142Z",
     "start_time": "2024-02-17T13:13:13.310510Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [00:38<00:00,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_120_333423/01.wav_G4_T2_R3\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_25_333136/01.wav_G1_T3_R6\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_99_333343/01.wav_G3_T4_R3\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_44_333214/01.wav_G2_T1_R4\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_90_333331/01.wav_G3_T3_R1\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_102_333346/01.wav_G3_T4_R6\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_37_333154/01.wav_G1_T5_R4\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_86_333324/01.wav_G3_T2_R4\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_132_333441/01.wav_G4_T4_R1\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_117_333417/01.wav_G4_T1_R7\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_106_333353/01.wav_G3_T5_R3\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_79_333314/01.wav_G3_T1_R4\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_24_333135/01.wav_G1_T3_R5\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_69_333251/01.wav_G2_T5_R1\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_129_333435/01.wav_G4_T3_R5\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_33_333147/01.wav_G1_T4_R7\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_91_333332/01.wav_G3_T3_R2\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_17_333125/01.wav_G1_T2_R5\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_133_333442/01.wav_G4_T4_R2\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_09_333114/01.wav_G1_T1_R4\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_05_333050/01.wav_G0_T5_R0\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_122_333425/01.wav_G4_T2_R5\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_47_333217/01.wav_G2_T1_R7\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_62_333241/01.wav_G2_T4_R1\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_06_333111/01.wav_G1_T1_R1\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_114_333414/01.wav_G4_T1_R4\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_108_333355/01.wav_G3_T5_R5\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_101_333345/01.wav_G3_T4_R5\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_77_333312/01.wav_G3_T1_R2\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_89_333327/01.wav_G3_T2_R7\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_84_333322/01.wav_G3_T2_R2\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_35_333152/01.wav_G1_T5_R2\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_127_333433/96.wav_G4_T3_R3\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_75_333257/01.wav_G2_T5_R7\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_123_333426/01.wav_G4_T2_R6\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_63_333242/01.wav_G2_T4_R2\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_144_333456/01.wav_G4_T5_R6\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_15_333123/01.wav_G1_T2_R3\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_93_333334/01.wav_G3_T3_R4\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_01_333010/02.wav_G0_T1_R0\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_01_333010/16.wav_G0_T1_R0\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_01_333010/17.wav_G0_T1_R0\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_01_333010/03.wav_G0_T1_R0\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_01_333010/15.wav_G0_T1_R0\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_01_333010/01.wav_G0_T1_R0\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_01_333010/14.wav_G0_T1_R0\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_01_333010/10.wav_G0_T1_R0\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_01_333010/04.wav_G0_T1_R0\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_01_333010/05.wav_G0_T1_R0\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_01_333010/11.wav_G0_T1_R0\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_01_333010/07.wav_G0_T1_R0\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_01_333010/13.wav_G0_T1_R0\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_01_333010/12.wav_G0_T1_R0\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_01_333010/06.wav_G0_T1_R0\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_01_333010/20.wav_G0_T1_R0\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_01_333010/08.wav_G0_T1_R0\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_01_333010/09.wav_G0_T1_R0\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_01_333010/19.wav_G0_T1_R0\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_01_333010/18.wav_G0_T1_R0\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_07_333112/01.wav_G1_T1_R2\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_76_333311/01.wav_G3_T1_R1\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_18_333126/01.wav_G1_T2_R6\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_139_333451/01.wav_G4_T5_R1\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_109_333356/01.wav_G3_T5_R6\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_30_333144/01.wav_G1_T4_R4\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_34_333151/01.wav_G1_T5_R1\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_81_333316/01.wav_G3_T1_R6\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_111_333411/01.wav_G4_T1_R1\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_138_333447/01.wav_G4_T4_R7\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_96_333337/01.wav_G3_T3_R7\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_04_333040/01.wav_G0_T4_R0\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_50_333223/01.wav_G2_T2_R3\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_42_333212/01.wav_G2_T1_R2\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_141_333453/01.wav_G4_T5_R3\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_27_333141/01.wav_G1_T4_R1\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_135_333444/01.wav_G4_T4_R4\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_80_333315/01.wav_G3_T1_R5\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_59_333235/01.wav_G2_T3_R5\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_70_333252/01.wav_G2_T5_R2\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_130_333436/01.wav_G4_T3_R6\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_22_333133/01.wav_G1_T3_R3\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_12_333117/01.wav_G1_T1_R7\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_83_333321/01.wav_G3_T2_R1\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_112_333412/01.wav_G4_T1_R2\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_41_333211/01.wav_G2_T1_R1\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_68_333247/01.wav_G2_T4_R7\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_52_333225/01.wav_G2_T2_R5\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_28_333142/01.wav_G1_T4_R2\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_143_333455/01.wav_G4_T5_R5\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_60_333236/01.wav_G2_T3_R6\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_72_333254/01.wav_G2_T5_R4\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_65_333244/01.wav_G2_T4_R4\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_57_333233/01.wav_G2_T3_R3\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_53_333226/01.wav_G2_T2_R6\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_116_333416/01.wav_G4_T1_R6\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_87_333325/01.wav_G3_T2_R5\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_103_333347/01.wav_G3_T4_R7\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_08_333113/01.wav_G1_T1_R3\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_02_333020/01.wav_G0_T2_R0\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_48_333221/01.wav_G2_T2_R1\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_45_333215/01.wav_G2_T1_R5\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_98_333342/01.wav_G3_T4_R2\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_36_333153/01.wav_G1_T5_R3\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_16_333124/01.wav_G1_T2_R4\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_78_333313/01.wav_G3_T1_R3\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_107_333354/01.wav_G3_T5_R4\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_32_333146/01.wav_G1_T4_R6\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_128_333434/01.wav_G4_T3_R4\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_121_333424/01.wav_G4_T2_R4\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_49_333222/01.wav_G2_T2_R2\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_125_333431/01.wav_G4_T3_R1\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_92_333333/01.wav_G3_T3_R3\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_88_333326/01.wav_G3_T2_R6\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_39_333156/01.wav_G1_T5_R6\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_118_333421/01.wav_G4_T2_R1\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_85_333323/01.wav_G3_T2_R3\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_104_333351/01.wav_G3_T5_R1\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_100_333344/01.wav_G3_T4_R4\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_115_333415/01.wav_G4_T1_R5\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_46_333216/01.wav_G2_T1_R6\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_54_333227/01.wav_G2_T2_R7\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_97_333341/01.wav_G3_T4_R1\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_31_333145/01.wav_G1_T4_R5\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_119_333422/01.wav_G4_T2_R2\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_38_333155/02.wav_G1_T5_R5\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_38_333155/01.wav_G1_T5_R5\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_14_333122/01.wav_G1_T2_R2\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_145_333457/01.wav_G4_T5_R7\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_105_333352/01.wav_G3_T5_R2\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_19_333127/01.wav_G1_T2_R7\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_26_333137/01.wav_G1_T3_R7\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_126_333432/01.wav_G4_T3_R2\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_74_333256/01.wav_G2_T5_R6\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_43_333213/01.wav_G2_T1_R3\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_66_333245/01.wav_G2_T4_R5\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_23_333134/01.wav_G1_T3_R4\n",
      "Error processing /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_23_333134/01_1.wav: string index out of range\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_10_333115/01.wav_G1_T1_R5\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_134_333443/01.wav_G4_T4_R3\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_131_333437/01.wav_G4_T3_R7\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_67_333246/01.wav_G2_T4_R6\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_51_333224/01.wav_G2_T2_R4\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_58_333234/01.wav_G2_T3_R4\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_55_333231/01.wav_G2_T3_R1\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_71_333253/01.wav_G2_T5_R3\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_11_333116/01.wav_G1_T1_R6\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_40_333157/01.wav_G1_T5_R7\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_140_333452/01.wav_G4_T5_R2\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_64_333243/01.wav_G2_T4_R3\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_21_333132/01.wav_G1_T3_R2\n",
      "Error processing /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_21_333132/01_1.wav: string index out of range\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_124_333427/01.wav_G4_T2_R7\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_136_333445/01.wav_G4_T4_R5\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_113_333413/01.wav_G4_T1_R3\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_03_333030/01.wav_G0_T3_R0\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_110_333357/01.wav_G3_T5_R7\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_94_333335/01.wav_G3_T3_R5\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_56_333232/01.wav_G2_T3_R2\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_20_333131/01.wav_G1_T3_R1\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_73_333255/01.wav_G2_T5_R5\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_61_333237/01.wav_G2_T3_R7\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_137_333446/01.wav_G4_T4_R6\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_82_333317/01.wav_G3_T1_R7\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_29_333143/01.wav_G1_T4_R3\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_142_333454/01.wav_G4_T5_R4\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_13_333121/01.wav_G1_T2_R1\n",
      "Processed /Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples/gtr_95_333336/01.wav_G3_T3_R6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "import re\n",
    "from pprint import pprint\n",
    "# from natsort import natsorted\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import multiprocessing\n",
    "\n",
    "base_folder_path = '/Users/yizhong/Documents/projects/artivoice/GTR-145-Demo/samples'\n",
    "\n",
    "# features_folder_path = f'{base_folder_path}-features'\n",
    "# if not os.path.exists(features_folder_path):\n",
    "#     os.makedirs(features_folder_path)\n",
    "\n",
    "# get all the folders under the base folder\n",
    "# wav_files = natsorted(glob.glob(os.path.join(base_folder_path, '**/*.wav'), recursive=True))\n",
    "wav_files = glob.glob(os.path.join(base_folder_path, '**/*.wav'), recursive=True)\n",
    "\n",
    "\n",
    "import multiprocess\n",
    "import numpy as np\n",
    "\n",
    "# wav_files_no_0_labels = [\n",
    "#     wav_file for wav_file in wav_files\n",
    "#     if not (int(re.findall(r'\\d+', wav_file)[-2][-3]) == 0 or int(re.findall(r'\\d+', wav_file)[-2][-1]) == 0)]\n",
    "\n",
    "labels_G = []\n",
    "labels_T = []\n",
    "labels_R = []\n",
    "features = []\n",
    "\n",
    "def process_file(wav_file):\n",
    "    # 从文件路径中提取数字\n",
    "    digits = re.findall(r'\\d+', wav_file)[-2]\n",
    "    try:\n",
    "        G = int(digits[-3])\n",
    "        T = int(digits[-2])\n",
    "        R = int(digits[-1])\n",
    "\n",
    "        # 提取特征\n",
    "        extractor = FeatureExtractor()\n",
    "        feature = extractor.extract_features(audio_path=wav_file)\n",
    "\n",
    "        # feature_file_path = os.path.join(features_folder_path, os.path.basename(wav_file) + '.npy')\n",
    "        # np.save(feature_file_path, feature)  # 保存特征到文件\n",
    "\n",
    "        return (G, T, R, feature, f'Processed {wav_file}_G{G}_T{T}_R{R}')\n",
    "    except Exception as e:\n",
    "        return None, None, None, None, f\"Error processing {wav_file}: {e}\"\n",
    "\n",
    "with multiprocess.Pool() as pool:\n",
    "    results = list(tqdm(pool.imap(process_file, wav_files), total=len(wav_files)))\n",
    "\n",
    "for G, T, R, feature, message in results:\n",
    "    if feature is not None:\n",
    "        labels_G.append(G)\n",
    "        labels_T.append(T)\n",
    "        labels_R.append(R)\n",
    "        features.append(feature)\n",
    "        print(message)\n",
    "    else:\n",
    "        print(message)\n",
    "\n",
    "features = np.array(features)\n",
    "labels_G = np.array(labels_G)\n",
    "labels_T = np.array(labels_T)\n",
    "labels_R = np.array(labels_R)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T13:19:14.169597Z",
     "start_time": "2024-02-17T13:19:14.150521Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.19042818e+01, 1.63108194e-02],\n       [1.98867368e+02, 3.83507428e-01],\n       [5.25858889e+01, 1.26463919e-01],\n       [1.29870532e+02, 1.98621011e-01],\n       [2.29517300e+02, 3.99050978e-01],\n       [2.39572837e+02, 3.99242580e-01],\n       [2.77680959e+02, 3.29907471e-01],\n       [1.74793736e+02, 2.57452263e-01],\n       [2.10792538e+02, 3.19205818e-01],\n       [1.97007048e+02, 3.73292308e-01],\n       [1.92216158e+02, 1.71895762e-01],\n       [1.93335445e+02, 3.69082473e-01],\n       [2.53164762e+02, 4.15919463e-01],\n       [2.40263949e+02, 2.71724125e-01],\n       [5.80040974e+01, 1.21660869e-01],\n       [1.37222942e+01, 1.60428473e-02],\n       [1.59574405e+01, 1.32639184e-02],\n       [2.21899580e+02, 2.25700556e-01],\n       [2.53558367e+02, 5.07045610e-01],\n       [2.82972309e+02, 5.50859063e-01],\n       [4.96512221e+01, 9.02662790e-02],\n       [1.11460955e+02, 2.34361814e-01],\n       [2.04906709e+02, 4.40533338e-01],\n       [2.26673051e+02, 2.76524656e-01],\n       [2.24663435e+02, 3.87680177e-01],\n       [8.26044743e+01, 1.21480823e-01],\n       [2.12739440e+02, 3.52936111e-01],\n       [1.20611559e+02, 1.54636491e-01],\n       [2.24575369e+02, 2.20140311e-01],\n       [5.20510324e+01, 8.18181773e-02],\n       [1.86097502e+02, 2.83767368e-01],\n       [1.81010307e+02, 4.45692401e-01],\n       [2.24458746e+02, 4.61382185e-01],\n       [2.20995407e+01, 1.76909689e-02],\n       [2.26424784e+02, 3.51729864e-01],\n       [7.27165691e+01, 1.56768819e-01],\n       [7.25051299e+01, 1.24246969e-01],\n       [3.71444375e+01, 8.39286432e-02],\n       [2.31592193e+02, 5.11699802e-01],\n       [2.90136707e+02, 4.61107039e-01],\n       [5.80098338e+01, 1.03613257e-01],\n       [2.26415964e+02, 5.19994021e-01],\n       [2.03899904e+02, 3.83304895e-01],\n       [2.64220522e+02, 4.64233642e-01],\n       [5.17741291e+01, 1.01003966e-01],\n       [2.19629296e+02, 2.65037369e-01],\n       [1.26387992e+02, 2.77788126e-01],\n       [1.58364443e+02, 2.50357652e-01],\n       [1.97214109e+02, 4.25973928e-01],\n       [1.44318264e+01, 1.68517846e-02],\n       [8.66087033e+01, 2.02548645e-01],\n       [1.80647260e+02, 3.00443759e-01],\n       [6.73281048e+01, 1.83547071e-01],\n       [1.07365582e+02, 1.68247084e-01],\n       [3.00043597e+02, 1.01059164e-01],\n       [2.49520071e+02, 4.03212204e-01],\n       [1.57632236e+02, 6.15611352e-01],\n       [2.81875925e+02, 5.95595525e-01],\n       [2.01135587e+02, 3.74829516e-01],\n       [2.18688882e+02, 2.47976689e-01],\n       [2.07665783e+01, 1.37160672e-02],\n       [1.78199329e+02, 5.65082788e-01],\n       [2.71411965e+02, 3.94480406e-01],\n       [1.24596812e+02, 2.01600352e-01],\n       [1.65027906e+01, 1.76225354e-02],\n       [1.15719000e+01, 1.57306067e-02],\n       [2.19840433e+02, 5.22515487e-01],\n       [1.54747846e+02, 1.83454323e-01],\n       [9.71430443e+00, 1.55336628e-02],\n       [2.58477896e+02, 1.96754353e-01],\n       [1.04019885e+02, 1.57184097e-01],\n       [1.19423220e+02, 1.55444602e-01],\n       [2.14462601e+02, 3.92001051e-01],\n       [6.14088130e+01, 1.04073730e-01],\n       [1.71436452e+02, 5.70134889e-01],\n       [2.41953697e+02, 6.24298388e-01],\n       [1.79321403e+02, 2.00518987e-01],\n       [7.40607695e+01, 1.57058308e-01],\n       [1.66378384e+01, 1.32189891e-02],\n       [2.68754810e+02, 4.66196690e-01],\n       [2.44593709e+02, 3.82485556e-01],\n       [1.90405041e+02, 2.85121398e-01],\n       [4.76384997e+01, 1.14068801e-01],\n       [1.55974363e+02, 1.87135392e-01],\n       [1.70624905e+01, 1.18278627e-02],\n       [1.84376181e+02, 2.63778015e-01],\n       [9.56282073e+01, 1.87247845e-01],\n       [2.21341489e+02, 2.92636526e-01],\n       [2.30133817e+01, 1.39926201e-02],\n       [2.60220166e+02, 4.77117681e-01],\n       [2.59867722e+02, 4.48452018e-01],\n       [7.14106135e+01, 1.51258339e-01],\n       [2.38624985e+02, 3.59889818e-01],\n       [2.64403965e+02, 4.43675962e-01],\n       [1.50790266e+01, 1.58550468e-02],\n       [5.79763353e+01, 1.34801694e-01],\n       [2.28164866e+02, 5.54670759e-01],\n       [4.70450510e+01, 9.34070392e-02],\n       [2.64192396e+01, 1.90647261e-02],\n       [1.59949834e+02, 3.92616522e-01],\n       [2.43558652e+02, 2.90374022e-01],\n       [3.92585004e+01, 1.12981382e-01],\n       [1.59057916e+02, 2.61199623e-01],\n       [8.60588095e+01, 9.00930858e-02],\n       [1.19248213e+02, 2.49735383e-01],\n       [1.82275910e+01, 1.38014925e-02],\n       [2.43045227e+02, 4.99154204e-01],\n       [2.38180903e+02, 4.03624789e-01],\n       [8.46371331e+01, 1.06090794e-01],\n       [1.21510134e+02, 2.33621917e-01],\n       [1.72884095e+02, 3.32781472e-01],\n       [2.23841583e+02, 3.30395782e-01],\n       [2.48468658e+02, 4.82157396e-01],\n       [2.52752934e+02, 4.54040043e-01],\n       [4.38727635e+01, 8.73693647e-02],\n       [1.21123280e+01, 1.16606352e-02],\n       [9.07681861e+01, 3.46811831e-01],\n       [8.61669468e+01, 1.33356949e-01],\n       [7.45217174e+01, 1.43021219e-01],\n       [7.53842847e+01, 1.84684917e-01],\n       [1.88836887e+02, 3.43186198e-01],\n       [5.07522190e+01, 1.13177651e-01],\n       [3.25773110e+02, 6.53652412e-01],\n       [1.70835199e+02, 5.10727879e-01],\n       [2.43183917e+02, 4.87651963e-01],\n       [2.90685783e+02, 5.06847979e-01],\n       [2.46027564e+02, 4.13939771e-01],\n       [2.05226418e+02, 2.18350364e-01],\n       [1.46140493e+02, 1.36518610e-01],\n       [1.26130808e+01, 1.18678279e-02],\n       [2.95840098e+02, 6.29707451e-01],\n       [1.21332462e+01, 1.52931457e-02]])"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels_R, test_size=0.2, random_state=32)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# minmax the features\n",
    "# scaler = MinMaxScaler()\n",
    "#\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "# check mean and std of the scaled features\n",
    "# print(f'Mean of the scaled features: {np.mean(X_train_scaled)}')\n",
    "# print(f'Std of the scaled features: {np.std(X_train_scaled)}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-17T13:13:57.963180Z",
     "start_time": "2024-02-17T13:13:57.927315Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T13:19:16.856497Z",
     "start_time": "2024-02-17T13:19:16.833610Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        18\n",
      "           1       0.67      1.00      0.80        18\n",
      "           2       0.00      0.00      0.00        15\n",
      "           3       0.00      0.00      0.00        14\n",
      "           4       0.27      0.61      0.37        18\n",
      "           5       0.00      0.00      0.00        16\n",
      "           6       0.26      0.71      0.38        17\n",
      "           7       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.45       132\n",
      "   macro avg       0.27      0.41      0.32       132\n",
      "weighted avg       0.30      0.45      0.35       132\n",
      "\n",
      "Test set report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       0.50      1.00      0.67         2\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.13      0.67      0.22         3\n",
      "           7       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.30        33\n",
      "   macro avg       0.20      0.33      0.24        33\n",
      "weighted avg       0.22      0.30      0.24        33\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yizhong/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yizhong/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yizhong/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yizhong/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yizhong/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yizhong/miniconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# t\n",
    "clf = make_pipeline(SVC(C=0.1, gamma=0.001, kernel='rbf'))\n",
    "# clf = make_pipeline(SVC())\n",
    "clf.fit(X_train, y_train)\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 在训练集上评估模型\n",
    "y_train_pred = clf.predict(X_train)\n",
    "print(\"Train set report:\")\n",
    "print(classification_report(y_train, y_train_pred))\n",
    "\n",
    "# 在测试集上进行预测\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "# 测试集评估\n",
    "print(\"Test set report:\")\n",
    "print(classification_report(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classification_report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# save the report as a text file\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassification_report.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 3\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain set report:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mclassification_report(y_train,\u001b[38;5;250m \u001b[39my_train_pred)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest set report:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mclassification_report(y_test,\u001b[38;5;250m \u001b[39my_test_pred)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# plot loss curve\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# plt.plot(clf[-1].loss_curve_)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classification_report' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# save the report as a text file\n",
    "with open('classification_report.txt', 'w') as f:\n",
    "    f.write(f\"Train set report:\\n{classification_report(y_train, y_train_pred)}\\n\\n\")\n",
    "    f.write(f\"Test set report:\\n{classification_report(y_test, y_test_pred)}\\n\\n\")\n",
    "\n",
    "# plot loss curve\n",
    "# plt.plot(clf[-1].loss_curve_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "#\n",
    "# param_grid = {\n",
    "#     'C': [0.1, 1, 10, 100, 1000],\n",
    "#     'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "#     'kernel': ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "# }\n",
    "#\n",
    "# grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "#\n",
    "# print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "# print(f\"Best score: {grid_search.best_score_}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all features shape\n",
    "print('y: ', y.shape)\n",
    "print('stft: ', stft.shape)\n",
    "print('mfcc: ', mfcc.shape)\n",
    "print('mel: ', mel.shape)\n",
    "print('contrast: ', contrast.shape)\n",
    "print('spectral centroid: ', spec_cent.shape)\n",
    "print('spectral bandwidth: ', spec_bw.shape)\n",
    "print('spectral rolloff: ', spec_rolloff.shape)\n",
    "print('spectral rolloff min: ', spec_rolloff_min.shape)\n",
    "print('f0: ', f0.shape)\n",
    "print('voiced flag: ', voiced_flag.shape)\n",
    "print('voiced probs: ', voiced_probs.shape) \n",
    "print('zero crossing rate: ', zcr.shape)\n",
    "print('flatness: ', flatness.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all features\n",
    "\n",
    "# mfcc\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.subplot(3, 3, 7)  # Change from (2, 4, 1) to (3, 3, 1)\n",
    "librosa.feature.mfcc(S=librosa.power_to_db(mel))\n",
    "\n",
    "librosa.display.specshow(mfcc, x_axis='time')\n",
    "\n",
    "plt.title('MFCC')\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "\n",
    "# mel spectrogram\n",
    "plt.subplot(3, 3, 2)  # Change from (2, 4, 2) to (3, 3, 2)\n",
    "ax = plt.gca()\n",
    "S_dB = librosa.power_to_db(mel, ref=np.max)\n",
    "librosa.display.specshow(S_dB, x_axis='time',\n",
    "                         y_axis='mel', sr=sr,\n",
    "                         fmax=sr/2, ax=ax)\n",
    "plt.title('Mel')\n",
    "plt.tight_layout()\n",
    "\n",
    "# contrast\n",
    "plt.subplot(3, 3, 3)  # Change from (2, 4, 3) to (3, 3, 3)\n",
    "librosa.display.specshow(contrast, x_axis='time')\n",
    "plt.title('Contrast')\n",
    "# plt.colorbar()\n",
    "plt.tight_layout()\n",
    "\n",
    "# spectral centroid\n",
    "plt.subplot(3, 3, 4)  # Change from (2, 4, 4) to (3, 3, 4)\n",
    "ax = plt.gca() # get current axis\n",
    "S, phase = librosa.magphase(librosa.stft(y=y))\n",
    "times = librosa.times_like(spec_cent)\n",
    "librosa.display.specshow(librosa.amplitude_to_db(S, ref=np.max),\n",
    "                         y_axis='log', x_axis='time', ax=ax)\n",
    "ax.plot(times, spec_cent[0], label='Spectral centroid', color='w')\n",
    "plt.title('Spectral Centroid')\n",
    "# plt.colorbar()\n",
    "plt.tight_layout()\n",
    "\n",
    "# spectral bandwidth\n",
    "plt.subplot(3, 3, 5)  # Change from (2, 4, 5) to (3, 3, 5)\n",
    "ax = plt.gca()  # 获取当前的Axes对象\n",
    "\n",
    "# band width\n",
    "times = librosa.times_like(spec_bw)\n",
    "centroid = librosa.feature.spectral_centroid(S=mel)\n",
    "ax.semilogy(times, spec_bw[0], label='Spectral bandwidth', color='b')  \n",
    "ax.set(ylabel='Hz', xticks=[], xlim=[times.min(), times.max()])\n",
    "ax.legend()\n",
    "ax.label_outer()\n",
    "\n",
    "librosa.display.specshow(librosa.amplitude_to_db(S, ref=np.max),\n",
    "                         y_axis='log', x_axis='time', ax=ax)\n",
    "\n",
    "ax.fill_between(times, np.maximum(0, centroid[0] - spec_bw[0]),\n",
    "                np.minimum(centroid[0] + spec_bw[0], sr/2),\n",
    "                alpha=0.5, label='Centroid +- bandwidth', color='r')  \n",
    "ax.plot(times, centroid[0], label='Spectral centroid', color='w')\n",
    "ax.legend(loc='lower right')\n",
    "plt.title('Spectral Bandwidth')\n",
    "\n",
    "# spectral rolloff\n",
    "plt.subplot(3, 3, 6)  # Change from (2, 4, 6) to (3, 3, 6)\n",
    "ax = plt.gca()  # 获取当前的Axes对象\n",
    "librosa.display.specshow(librosa.amplitude_to_db(S, ref=np.max),\n",
    "                         y_axis='log', x_axis='time', ax=ax)\n",
    "ax.plot(librosa.times_like(spec_rolloff), spec_rolloff[0], label='Roll-off frequency (0.99)', color='c')\n",
    "ax.plot(librosa.times_like(spec_rolloff), spec_rolloff_min[0], color='m', label='Roll-off frequency (0.01)')\n",
    "ax.legend(loc='lower right')\n",
    "plt.title('Spectral Rolloff')\n",
    "\n",
    "# pitch\n",
    "plt.subplot(3, 3, 1)  # Change from (2, 4, 7) to (3, 3, 7)\n",
    "ax = plt.gca()\n",
    "times_f0 = librosa.times_like(f0)\n",
    "D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)S\n",
    "librosa.display.specshow(D, x_axis='time', y_axis='log', ax=ax)\n",
    "ax.set(title='pYIN fundamental frequency estimation')\n",
    "ax.plot(times_f0, f0, label='f0', color='cyan', linewidth=3)\n",
    "ax.legend(loc='upper right')\n",
    "\n",
    "# zero crossing rate\n",
    "plt.subplot(3, 3, 8)  # Change from (2, 4, 8) to (3, 3, 8)\n",
    "plt.plot(zcr[0])\n",
    "plt.title('Zero Crossing Rate')\n",
    "plt.tight_layout()\n",
    "\n",
    "# flatness\n",
    "plt.subplot(3, 3, 9)  # Add new subplot (3, 3, 9)\n",
    "plt.plot(flatness[0])\n",
    "plt.title('Spectral Flatness')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gtr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
